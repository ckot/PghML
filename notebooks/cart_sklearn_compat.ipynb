{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How to roll your own scikit-learn compatible algorithm\n",
    "\n",
    "\n",
    "In my presentation, I showed how you could simply create a class subclassed from **object**, provide the following interface, and have code which worked with most scikit-learn utility functions/classes\n",
    "\n",
    "```\n",
    "def __init__(self, paramA=defaultvalA, paramB=defaultvalB)\n",
    "  \n",
    "def fit(self, X, y, **option_fit_params)\n",
    "\n",
    "def predict(self, X)\n",
    "\n",
    "def score(self, X, y, sample_weight=None)\n",
    "\n",
    "def get_params(self, deep=True)\n",
    "\n",
    "def set_params(self, **params)\n",
    "```\n",
    "\n",
    "\n",
    "## What I've learned since my presentation\n",
    "\n",
    "If I had instead subclassed from sklearn's  `base.BaseEstimator`, I would have inherited:\n",
    "\n",
    "* `get_params()`  - BaseEstimator introspects your __init__() and returns a dict of your named params mapped to their values\n",
    "\n",
    "* `set_params()`  - this method is always the same\n",
    "\n",
    "* `__repr__()`, which makes use of `get_params()`\n",
    "\n",
    "\n",
    "If I had made use of `base.ClassifierMixin`, I would have inherited:\n",
    "* `score()` - which uses `sklearn.metrics.accuracy_score()`\n",
    "\n",
    "It automatically sets the following attribute for you:\n",
    "* `estimator_type_ = \"classifier\"`\n",
    "\n",
    "If instead you're implementing a regression estimator, you could make use of `base.RegressorMixin` which provides\n",
    "* `score()` which uses `sklearn.metrics.r2_score`\n",
    "\n",
    "and sets the attribute:\n",
    "* `estimator_type_ = \"regressor\"`\n",
    "\n",
    "### Some serious reduction in boilerplate!\n",
    "Making use of these classes and mixins allows you spend more time on implementing your actual algoritm, meaning the only public methods you need to implement are:\n",
    "\n",
    "```\n",
    "def __init__(self, paramA=defaultvalA, paramB=defaultvalB)\n",
    "    \"\"\"you shouldn't do any modification of the param values passed in as they can\n",
    "    also be set by the set_params() method.  do sanity checking/modification of values\n",
    "    in fit()\n",
    "    \"\"\"\n",
    "    self.paramA = paramA\n",
    "    self.paramB = paramB\n",
    "\n",
    "\n",
    "def fit(self, X, y, **option_fit_params)\n",
    "    \"\"\"train your model\n",
    "       do sanity checking of X, y, and parameters settable in __init__() here\n",
    "       as those parameters can also be passed in via set_params()\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def predict(self, X)\n",
    "    \"\"\"to make use of your model (return a classication or some value from your regressor\"\"\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# installs 'PghML' in sys.path (if it isn't there already)\n",
    "import setup_sys_path \n",
    "\n",
    "# loader function for my dataset\n",
    "from pgh_ml_py.datasets import load_banknote_authentication\n",
    "# my decision tree implementation\n",
    "from pgh_ml_py.sklearn_compat.tree.cart_decision_tree import CartDecisionTreeClassifier, display_tree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# useful sklearn functions/Classes which we wish to be able to leverage (the point of making our code compatible)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = load_banknote_authentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = dataset.dataframe\n",
    "X = dataset.data\n",
    "y = dataset.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = CartDecisionTreeClassifier(criterion=\"entropy\", max_depth=5, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CartDecisionTreeClassifier(criterion='entropy', max_depth=5,\n",
       "              min_samples_split=5, splitter=u'best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Following sklearn's conventions for decision trees, my implementation's fit method sets the following 2 attributes:\n",
    "\n",
    "* `clf.tree_`  - the underlying representation of the decision tree\n",
    "\n",
    "* `clf.classes_` - the set of unique classes in y\n",
    "\n",
    "\n",
    "\n",
    "### Here I call my ad_hoc function, display_tree(), which understands my decision trees representation makes use of these attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if feat[3] <= 2.450: (impurity: 0.606 num_samples: 1029 [570 459])\n",
      "T-> 0\n",
      "F-> 0\n"
     ]
    }
   ],
   "source": [
    "display_tree(clf.tree_, clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ok, great, but let's actually try and do something with my tree.  Let's call predict() on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.predict(test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## yikes!\n",
    "\n",
    "What's happening here ??? As you can see, it *works* but spits out an ugly deprecation warning\n",
    "\n",
    "Sklearn classfiers predict methods expect an **array** of rows, so if we're passing in a single row of data we simply need to pass it as [row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.predict([test_X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### And let's see how accurate my tree is by passing in full test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55976676384839652"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ok. \n",
    "That's fine for demonstrating how to fit/predict/score a single tree, but let's do a cross validation with 5 folds\n",
    "#### New\n",
    "I've discovered that cross_val_score() and some other cross-validation functions/Class allow you to use all cpus/cores by passing a named-parameter `n_jobs=-1` (otherwise it defaults to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(clf, dataset.data, dataset.target, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hmm. something looks **very** wrong here\n",
    "The original code scored ~80%.  Did I break something in my refactoring?  Lets take a look at the data (like you really **should** do prior to doing anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ok,  I *think* I'm seeing a pattern. Let's print out some more of the dataset to make sure I'm not hallucinating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Here's the problem with what I did\n",
    "\n",
    "It turns out that my original function which created k-folds was randomizing (shuffling) the order of records, but that's not happening here\n",
    "\n",
    "As you can see, **all** of the rows labeled **0** are in the **1st half** of the dataset while all the rows labeled **1** are in the **2nd half** of the dataset.  \n",
    "\n",
    "By default, if you simply pass in an int for the cv param it uses KFold which doesn't deal with this. \n",
    "\n",
    "### Let's make use of StratifiedKFold instead to make sure that all of our folds have the classes balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=np.random.RandomState(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(clf, dataset.data, dataset.target, n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ok, great!  These values are pretty much in sync with the original blog post I based this off of.  That's a relief - I didn't break anything in all of my refactoring.\n",
    "\n",
    "So far, I've simply made use of my class using it's default values of max_depth=5 and min_samples_split=20\n",
    "\n",
    "### Let's make use of sklearn's GridSearchCV to try automatically optimize values for these parameters. \n",
    "\n",
    "Of course, this can take a while, so I'll keep the ranges of values to a reasonable size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(3, 6), 'min_samples_split': range(2, 21, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt = CartDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(dt, parameters, cv=cv, n_jobs=-1, verbose=True)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### After running fit(), the GridSearchCV has a bunch of attributes set.  The ones I found most useful were:\n",
    "* cv\\_results\\_      - lots of details which can be imported into pandas as a dataframe\n",
    "* best\\_score\\_      - score of the best result\n",
    "* best\\_params\\_     - dict of the best parameter values discovered\n",
    "* best\\_estimator\\_  - the best estimator object (useful as you can inspect it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"\"\"\n",
    "best score: %f\n",
    "best params: %s\n",
    "\"\"\" % (clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_tree = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "display_tree(best_tree.tree_, best_tree.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Going Forward\n",
    "\n",
    "### More attributes.\n",
    "Decision Trees in sklearn provide the following attributes.  What I'm not sure about is whether they are simply useful \n",
    "for allowing the model developer to inspect what was learned, or if certain utility functions/Classes actually make use of them.\n",
    "\n",
    "* `classes_` - I implemented this one. simply the unique set of labels \n",
    "\n",
    "\n",
    "* `tree_` - I implemented this as well, simply provides access to the data structure which represents the tree\n",
    "\n",
    "\n",
    "* `n_features_` -  I *believe* this should be the number of columns in X, or simply `X.shape[1]`\n",
    "\n",
    "\n",
    "* `n_outputs_` - I *believe* this represents how many columns are in y, which is typically 1, but is computed as `y.ndim`  Perhaps this is more useful when doing multi-label/class/output stuff\n",
    "\n",
    "\n",
    "* `n_classes_` - I *believe* this should simply be  `len(classes_)`\n",
    "\n",
    "\n",
    "* `max_features_` - how many features were considered when determining the best splits\n",
    "\n",
    "Also they provide more named-parameters in their constructors. I'm currently providing:\n",
    "* `max_depth`\n",
    "\n",
    "\n",
    "* `min_samples_split`\n",
    "\n",
    "### More Hyper-Parameters\n",
    "Scikit-learn decision trees provide the following named parameters in their constructors:\n",
    "\n",
    "* `max_depth=None` - I implemented this one, defaults to unlimited depth\n",
    "\n",
    "* `min_samples_split=2` - I implented this one, The minimum number of samples required for a branch to split\n",
    "\n",
    "\n",
    "* For classifiers:\n",
    "    * `criterion=\"gini\"` - the other choice being \"entropy\". I could add support for using this as my metric for selecting the best split\n",
    "\n",
    "\n",
    "* For regressors:\n",
    "    * `criterion=\"mse\"`  - the other choices being \"friedman_mse\", and \"mae\"\n",
    " \n",
    " \n",
    "* `splitter=\"best\"`  the other choice being \"random\". My implementation is \"best\".  I *believe* \"random\" would be useful for generating numerous trees for Random Forests\n",
    "\n",
    "\n",
    "* `max_features` defaults to the number of features, different values determine how many features should be considered when trying to determine the best split\n",
    "\n",
    "\n",
    "* `min_samples_leaf` the minimum number of samples required to represent a leaf node. I'm guessing this is used to prune the parent node and replace it with a leaf\n",
    "\n",
    "\n",
    "* `max_leaf_nodes=None` - grows tree with 'max_leaf_nodes' in best-first fashion. best nodes are defined as relative reduction in impurity. If none, unlimited number of leaf nodes\n",
    "\n",
    "\n",
    "* `min_weight_fraction_leaf=0` - minimum weighted fraction of the sum total of weights (of all input samples) required to be a leaf node. 0 means samples all have the same weight\n",
    "\n",
    "\n",
    "* `class_weight=None`  if 'None' all classes have weight of 1, if \"balanced\" each class's weight is inversely proportional to class frequencies in 'y'. It can also be a dict of {class_label: weight, ...} or for multi-label a list of dicts in this format\n",
    "\n",
    "\n",
    "* `random_state=None` - scikit-learn always randomizes the feature indices to use when calculating splits, even if max_features is the same as n_features_.  this parameter simply gives you control to make multiple runs deterministic\n",
    "\n",
    "\n",
    "* `min_impurity_split=1e-7` threshold to prevent splits if a node's impurity is below, and instead generate a leaf node\n",
    "\n",
    "\n",
    "* `presort=False` whether to presort the data to attempt to speed up finding the best splits. A setting of True may slow down fitting of large datasets (if max_depth is too high), but may speed up things up for small datasets \n",
    "\n",
    "\n",
    "Perhaps, by incorporating such hyper-parameters into my algorithm, and thus being able optimize for them,  I can improve the trees I generate.  \n",
    "\n",
    "Again, my purpose isn't to re-implement scikit-learn's decision trees, but rather implement an algoritm which is compatable with sklearn, so that I can explore how the algorithm works.  Figuring out what additional hyper-parameters are relevant to decision trees would simply allow me to explore improving the algorithm.  Perhaps other hyper-parameters could be found from different implementations or my own ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References\n",
    "\n",
    "Original blog post I got the algorithm from: http://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "\n",
    "sklearn documentation on rolling your own estimator: http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Gini index calculation\n",
    "$$count_k = 1/ Nm \\sum_{x_i in Rm} I(yi = k)$$\n",
    "$$index = \\sum_{k=0}^{K-1} count_k (1 - count_k)$$\n",
    "$$      = 1 - \\sum_{k=0}^{K-1} count_k ** 2$$\n",
    "\n",
    "Entropy calculation\n",
    "same calculation for $count_k$\n",
    "\n",
    "cross entropy\n",
    "$$crossEntropy = -\\sum_{k=0}^{K-1} count_k log(count_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.where(arr < 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(np.bincount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.array(np.arange(7,10))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(7,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([1.91240001, 2.4333, 4.2442424, 4.35353535])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(np.isclose(arr, 1.9124001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([1,0,1,1,0,0,1,1,0,0,0,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, freqs = np.unique(arr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = freqs / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = freqs / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
