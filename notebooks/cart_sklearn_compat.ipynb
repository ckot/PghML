{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How to implement a learning algorithm which is sklearn-compatible \n",
    "(actually more like demonstrating that it works, see my implementation for details on how to actually do it)\n",
    "\n",
    "First off you need to implement you algorithm as a class and provide named parameters with default values in the\n",
    "constructor\n",
    "\n",
    "ex) \n",
    "\n",
    "**def \\__init\\__(self, max_depth=5, min_samples_split=20)**\n",
    "\n",
    "then you will need to provide the following methods at the bare minimum\n",
    "\n",
    "**def fit(self, X, y)**   - to train your model\n",
    "\n",
    "**def predict(self, X)**  - to make use of your model\n",
    "\n",
    "**def score(self, X, y)**  - for evaluating your model's accuracy\n",
    "\n",
    "however, this will only get you so far, and primarily provides the same \"feel\" as a scikit learn estimator.  to make it compatible with more things, you should also implement:\n",
    "\n",
    "**def get_params(self)**  - simply returns a dict of the current parameter values\n",
    "\n",
    "**def set_params(self, \\*\\*params)** - allows you to override parameter values passed to the constructor\n",
    "\n",
    "Anyway, that should get you pretty far, as I'll show below. There is a link at the end of this notebook to the\n",
    "scikit-learn documentation which provides more details (such as what to subclass, and mixins you can use), but as we'll see soon, you can get pretty far doing the bare minimum - I simply sublassed 'object' and provided the public interface described above)\n",
    "\n",
    "## Using reusable code in an Ipython notebook\n",
    "Jupyter's Ipython kernel (at least currently) doesn't allow you to import python\n",
    "packages/modules from other directories unless they are in sys.path\n",
    "\n",
    "I've added a **config_notebook.py** in the 'notebooks' subdir from which\n",
    "you can **import setup_pgh_ml_path** from, call it, and then you'll be able\n",
    "to import python code from any directory below PghML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# install 'PghML' in sys.path (if it isn't there already)\n",
    "from config_notebook import setup_pgh_ml_path\n",
    "setup_pgh_ml_path()\n",
    "\n",
    "# loader function for my dataset\n",
    "from datasets.loaders import load_banknote_authentication\n",
    "# my decision tree implementation\n",
    "from pgh_ml_py.sklearn_compat.tree.cart_decision_tree import CartDecisionTreeClassifier, display_tree\n",
    "\n",
    "# useful sklearn functions/Classes which we wish to be able to leverage (the point of making our code compatible)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "# other dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# my custom dataset loader function. typically you'll have it return some fields using the conventions\n",
    "# data -> the features matrix\n",
    "# target -> the labels vector\n",
    "# in addition, I'm also returning 'dataframe' which is the original pandas dataframe I loaded, so we can analyze\n",
    "# the data as well\n",
    "dataset = load_banknote_authentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = dataset.dataframe\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 4)\n",
      "(1029,)\n",
      "(343, 4)\n",
      "(343,)\n"
     ]
    }
   ],
   "source": [
    "print train_X.shape\n",
    "print train_y.shape\n",
    "print test_X.shape\n",
    "print test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = CartDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CartDecisionTreeClassifier(max_depth=5, min_samples_split=20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following sklearn's conventions for decision trees, my implementation's fit method sets the following 2 attributes:\n",
    "\n",
    "clf.tree_  - the underlying representation of the decision tree\n",
    "\n",
    "clf.classes_ - the set of unique classes in y\n",
    "\n",
    "my ad_hoc function **display_tree()** which understands my decision trees representation makes use of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if feat[0] <= 1.594: (gini: 0.990 samples: 1029 [566, 463])\n",
      "T-> if feat[1] <= 9.748: (gini: 0.826 samples: 650 [194, 456])\n",
      "  T-> if feat[0] <= -7.042: (gini: 0.754 samples: 609 [153, 456])\n",
      "    T-> 1\n",
      "    F-> 1\n",
      "  F-> if feat[0] <= -2.226: (gini: 0.000 samples: 41 [41, 0])\n",
      "    T-> 0\n",
      "    F-> if feat[0] <= -2.226: (gini: 0.000 samples: 29 [29, 0])\n",
      "      T-> 0\n",
      "      F-> 0\n",
      "F-> if feat[2] <= -4.929: (gini: 0.066 samples: 379 [372, 7])\n",
      "  T-> 1\n",
      "  F-> if feat[0] <= 1.594: (gini: 0.040 samples: 376 [372, 4])\n",
      "    T-> 0\n",
      "    F-> 0\n"
     ]
    }
   ],
   "source": [
    "display_tree(clf.tree_, clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ok, great, but let's actually try and do something with my tree.  Let's call predict() on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Macintosh_HD_2/Users/ckot/ml/venv/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**yikes!** what's happening here ??? As you can see, it *works* but spits out an ugly deprecation warning\n",
    "\n",
    "Sklearn classfiers predict methods expect an **array** of rows, so if we're passing in a single row of data we simply need to pass it as [row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([test_X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And let's see how accurate my tree is by passing in full test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.79883381924198"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ok. That's fine for demonstrating how to fit/predict/score a single tree, but let's do a cross validation with 5 folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.54545455,  69.09090909,  76.64233577,  37.59124088,  28.46715328])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, dataset.data, dataset.target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hmm. something looks **very** wrong here,  the original code scored ~80%.  Did I break something in my refactoring?  Lets take a look at the data (like I **should** have prior to doing anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  label\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  label\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ok,  I *think* I'm seeing a pattern. Let's print out some more of the dataset to make sure I'm not hallucinating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.621600</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.807300</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.545900</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.458600</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.866000</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.924200</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.456600</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.011200</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329240</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.571800</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.368400</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.960600</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.591200</td>\n",
       "      <td>3.01290</td>\n",
       "      <td>0.728880</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.092200</td>\n",
       "      <td>-6.81000</td>\n",
       "      <td>8.463600</td>\n",
       "      <td>-0.602160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.203200</td>\n",
       "      <td>5.75880</td>\n",
       "      <td>-0.753450</td>\n",
       "      <td>-0.612510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.535600</td>\n",
       "      <td>9.17720</td>\n",
       "      <td>-2.271800</td>\n",
       "      <td>-0.735350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.224700</td>\n",
       "      <td>8.77790</td>\n",
       "      <td>-2.213500</td>\n",
       "      <td>-0.806470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.989900</td>\n",
       "      <td>-2.70660</td>\n",
       "      <td>2.394600</td>\n",
       "      <td>0.862910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.899300</td>\n",
       "      <td>7.66250</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>-3.110800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.576800</td>\n",
       "      <td>10.84300</td>\n",
       "      <td>2.546200</td>\n",
       "      <td>-2.936200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.404000</td>\n",
       "      <td>8.72610</td>\n",
       "      <td>-2.991500</td>\n",
       "      <td>-0.572420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.676500</td>\n",
       "      <td>-3.38950</td>\n",
       "      <td>3.489600</td>\n",
       "      <td>1.477100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.671900</td>\n",
       "      <td>3.06460</td>\n",
       "      <td>0.371580</td>\n",
       "      <td>0.586190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.803550</td>\n",
       "      <td>2.84730</td>\n",
       "      <td>4.343900</td>\n",
       "      <td>0.601700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.447900</td>\n",
       "      <td>-4.87940</td>\n",
       "      <td>8.342800</td>\n",
       "      <td>-2.108600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.242300</td>\n",
       "      <td>11.02720</td>\n",
       "      <td>-4.353000</td>\n",
       "      <td>-4.101300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.786700</td>\n",
       "      <td>7.89020</td>\n",
       "      <td>-2.619600</td>\n",
       "      <td>-0.487080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.329200</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.571800</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.936200</td>\n",
       "      <td>10.16220</td>\n",
       "      <td>-3.823500</td>\n",
       "      <td>-4.017200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.935840</td>\n",
       "      <td>8.88550</td>\n",
       "      <td>-1.683100</td>\n",
       "      <td>-1.659900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.433800</td>\n",
       "      <td>9.88700</td>\n",
       "      <td>-4.679500</td>\n",
       "      <td>-3.748300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.705700</td>\n",
       "      <td>-5.49810</td>\n",
       "      <td>8.336800</td>\n",
       "      <td>-2.871500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.143200</td>\n",
       "      <td>-3.74130</td>\n",
       "      <td>5.577700</td>\n",
       "      <td>-0.635780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.382140</td>\n",
       "      <td>8.39090</td>\n",
       "      <td>2.162400</td>\n",
       "      <td>-3.740500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.563300</td>\n",
       "      <td>9.81870</td>\n",
       "      <td>-4.411300</td>\n",
       "      <td>-3.225800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.890600</td>\n",
       "      <td>-3.35840</td>\n",
       "      <td>3.420200</td>\n",
       "      <td>1.090500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>-1.747900</td>\n",
       "      <td>-5.82300</td>\n",
       "      <td>5.869900</td>\n",
       "      <td>1.212000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>-0.959230</td>\n",
       "      <td>-6.71280</td>\n",
       "      <td>4.985700</td>\n",
       "      <td>0.328860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1.345100</td>\n",
       "      <td>0.23589</td>\n",
       "      <td>-1.878500</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>2.227900</td>\n",
       "      <td>4.09510</td>\n",
       "      <td>-4.803700</td>\n",
       "      <td>-2.111200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1.257200</td>\n",
       "      <td>4.87310</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-5.874100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>-5.385700</td>\n",
       "      <td>9.12140</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-5.918100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>-2.978600</td>\n",
       "      <td>2.34450</td>\n",
       "      <td>0.526670</td>\n",
       "      <td>-0.401730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>-1.585100</td>\n",
       "      <td>-2.15620</td>\n",
       "      <td>1.708200</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>-0.218880</td>\n",
       "      <td>-2.20380</td>\n",
       "      <td>-0.095400</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1.318300</td>\n",
       "      <td>1.90170</td>\n",
       "      <td>-3.311100</td>\n",
       "      <td>0.065071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1.489600</td>\n",
       "      <td>3.42880</td>\n",
       "      <td>-4.030900</td>\n",
       "      <td>-1.425900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>0.115920</td>\n",
       "      <td>3.22190</td>\n",
       "      <td>-3.430200</td>\n",
       "      <td>-2.845700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>-3.392400</td>\n",
       "      <td>3.35640</td>\n",
       "      <td>-0.720040</td>\n",
       "      <td>-3.523300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>-6.163200</td>\n",
       "      <td>8.70960</td>\n",
       "      <td>-0.216210</td>\n",
       "      <td>-3.634500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>-4.078600</td>\n",
       "      <td>2.92390</td>\n",
       "      <td>0.870260</td>\n",
       "      <td>-0.653890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>-2.589900</td>\n",
       "      <td>-0.39110</td>\n",
       "      <td>0.934520</td>\n",
       "      <td>0.429720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-0.19038</td>\n",
       "      <td>-0.905970</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>0.066129</td>\n",
       "      <td>2.49140</td>\n",
       "      <td>-2.940100</td>\n",
       "      <td>-0.621560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>-0.247450</td>\n",
       "      <td>1.93680</td>\n",
       "      <td>-2.469700</td>\n",
       "      <td>-0.805180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>-1.573200</td>\n",
       "      <td>1.06360</td>\n",
       "      <td>-0.712320</td>\n",
       "      <td>-0.838800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>-2.166800</td>\n",
       "      <td>1.59330</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>-1.678000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>-1.166700</td>\n",
       "      <td>-1.42370</td>\n",
       "      <td>2.924100</td>\n",
       "      <td>0.661190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>-2.839100</td>\n",
       "      <td>-6.63000</td>\n",
       "      <td>10.484900</td>\n",
       "      <td>-0.421130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>-4.504600</td>\n",
       "      <td>-5.81260</td>\n",
       "      <td>10.886700</td>\n",
       "      <td>-0.528460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>-2.410000</td>\n",
       "      <td>3.74330</td>\n",
       "      <td>-0.402150</td>\n",
       "      <td>-1.295300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.406140</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.450100</td>\n",
       "      <td>-0.559490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.388700</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.477400</td>\n",
       "      <td>0.341790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.750300</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.593200</td>\n",
       "      <td>-2.777100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.563700</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.393000</td>\n",
       "      <td>-1.282300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.541900</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.684200</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness   curtosis   entropy  label\n",
       "0     3.621600   8.66610  -2.807300 -0.446990      0\n",
       "1     4.545900   8.16740  -2.458600 -1.462100      0\n",
       "2     3.866000  -2.63830   1.924200  0.106450      0\n",
       "3     3.456600   9.52280  -4.011200 -3.594400      0\n",
       "4     0.329240  -4.45520   4.571800 -0.988800      0\n",
       "5     4.368400   9.67180  -3.960600 -3.162500      0\n",
       "6     3.591200   3.01290   0.728880  0.564210      0\n",
       "7     2.092200  -6.81000   8.463600 -0.602160      0\n",
       "8     3.203200   5.75880  -0.753450 -0.612510      0\n",
       "9     1.535600   9.17720  -2.271800 -0.735350      0\n",
       "10    1.224700   8.77790  -2.213500 -0.806470      0\n",
       "11    3.989900  -2.70660   2.394600  0.862910      0\n",
       "12    1.899300   7.66250   0.153940 -3.110800      0\n",
       "13   -1.576800  10.84300   2.546200 -2.936200      0\n",
       "14    3.404000   8.72610  -2.991500 -0.572420      0\n",
       "15    4.676500  -3.38950   3.489600  1.477100      0\n",
       "16    2.671900   3.06460   0.371580  0.586190      0\n",
       "17    0.803550   2.84730   4.343900  0.601700      0\n",
       "18    1.447900  -4.87940   8.342800 -2.108600      0\n",
       "19    5.242300  11.02720  -4.353000 -4.101300      0\n",
       "20    5.786700   7.89020  -2.619600 -0.487080      0\n",
       "21    0.329200  -4.45520   4.571800 -0.988800      0\n",
       "22    3.936200  10.16220  -3.823500 -4.017200      0\n",
       "23    0.935840   8.88550  -1.683100 -1.659900      0\n",
       "24    4.433800   9.88700  -4.679500 -3.748300      0\n",
       "25    0.705700  -5.49810   8.336800 -2.871500      0\n",
       "26    1.143200  -3.74130   5.577700 -0.635780      0\n",
       "27   -0.382140   8.39090   2.162400 -3.740500      0\n",
       "28    6.563300   9.81870  -4.411300 -3.225800      0\n",
       "29    4.890600  -3.35840   3.420200  1.090500      0\n",
       "...        ...       ...        ...       ...    ...\n",
       "1342 -1.747900  -5.82300   5.869900  1.212000      1\n",
       "1343 -0.959230  -6.71280   4.985700  0.328860      1\n",
       "1344  1.345100   0.23589  -1.878500  1.325800      1\n",
       "1345  2.227900   4.09510  -4.803700 -2.111200      1\n",
       "1346  1.257200   4.87310  -5.286100 -5.874100      1\n",
       "1347 -5.385700   9.12140  -0.419290 -5.918100      1\n",
       "1348 -2.978600   2.34450   0.526670 -0.401730      1\n",
       "1349 -1.585100  -2.15620   1.708200  0.901700      1\n",
       "1350 -0.218880  -2.20380  -0.095400  0.564210      1\n",
       "1351  1.318300   1.90170  -3.311100  0.065071      1\n",
       "1352  1.489600   3.42880  -4.030900 -1.425900      1\n",
       "1353  0.115920   3.22190  -3.430200 -2.845700      1\n",
       "1354 -3.392400   3.35640  -0.720040 -3.523300      1\n",
       "1355 -6.163200   8.70960  -0.216210 -3.634500      1\n",
       "1356 -4.078600   2.92390   0.870260 -0.653890      1\n",
       "1357 -2.589900  -0.39110   0.934520  0.429720      1\n",
       "1358 -1.011600  -0.19038  -0.905970  0.003003      1\n",
       "1359  0.066129   2.49140  -2.940100 -0.621560      1\n",
       "1360 -0.247450   1.93680  -2.469700 -0.805180      1\n",
       "1361 -1.573200   1.06360  -0.712320 -0.838800      1\n",
       "1362 -2.166800   1.59330   0.045122 -1.678000      1\n",
       "1363 -1.166700  -1.42370   2.924100  0.661190      1\n",
       "1364 -2.839100  -6.63000  10.484900 -0.421130      1\n",
       "1365 -4.504600  -5.81260  10.886700 -0.528460      1\n",
       "1366 -2.410000   3.74330  -0.402150 -1.295300      1\n",
       "1367  0.406140   1.34920  -1.450100 -0.559490      1\n",
       "1368 -1.388700  -4.87730   6.477400  0.341790      1\n",
       "1369 -3.750300 -13.45860  17.593200 -2.777100      1\n",
       "1370 -3.563700  -8.38270  12.393000 -1.282300      1\n",
       "1371 -2.541900  -0.65804   2.684200  1.195200      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### It turns out that my original function which created k-folds was randomizing (shuffling) the order of records, but that's not happening here\n",
    "\n",
    "As you can see, **all** of the rows labeled **0** are in the **1st half** of the dataset while all the rows labeled **1** are in the **2nd half** of the dataset.  \n",
    "\n",
    "By default, if you simply pass in an int for the cv param it uses KFold which doesn't deal with this. \n",
    "\n",
    "### Let's make use of StratifiedKFold instead to make sure that all of our folds have the classes balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=np.random.RandomState(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 84.        ,  81.81818182,  83.21167883,  83.21167883,  83.21167883])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, dataset.data, dataset.target, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ok, great!  These values are pretty much in sync with the original blog post I based this off of.  That's a relief - I didn't break anything in all of my refactoring.\n",
    "\n",
    "So far, I've simply made use of my class using it's default values of max_depth=5 and min_samples_split=20\n",
    "\n",
    "### Let's make use of sklearn's GridSearchCV to try automatically optimize values for these parameters. \n",
    "\n",
    "Of course, this can take a while, so I'll keep the ranges of values to a reasonable size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(3, 6), 'min_samples_split': range(10, 26, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt = CartDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedKFold(n_splits=5,\n",
      "        random_state=<mtrand.RandomState object at 0x112ae2c80>,\n",
      "        shuffle=True),\n",
      "       error_score='raise',\n",
      "       estimator=CartDecisionTreeClassifier(max_depth=5, min_samples_split=20),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'min_samples_split': [10, 15, 20, 25], 'max_depth': [3, 4, 5]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(dt, parameters, cv=cv, verbose=True)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   47.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5,\n",
       "        random_state=<mtrand.RandomState object at 0x112ae2c80>,\n",
       "        shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=CartDecisionTreeClassifier(max_depth=5, min_samples_split=20),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [10, 15, 20, 25], 'max_depth': [3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### After running fit(), the GridSearchCV has a bunch of attributes set.  The ones I found most useful were:\n",
    "* cv\\_results\\_      - lots of details which can be imported into pandas as a dataframe\n",
    "* best\\_score\\_      - score of the best result\n",
    "* best\\_params\\_     - dict of the best parameter values discovered\n",
    "* best\\_estimator\\_  - the best estimator object (useful as you can inspect it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840534</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'min_samples_split': 10, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779057</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'min_samples_split': 15, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.773153</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'min_samples_split': 20, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.771235</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'min_samples_split': 25, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.775854</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'min_samples_split': 10, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.776714</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'min_samples_split': 15, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.777320</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'min_samples_split': 20, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'min_samples_split': 25, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.777278</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'min_samples_split': 10, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.775073</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'min_samples_split': 15, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.791320</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'min_samples_split': 20, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.785110</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>83.163265</td>\n",
       "      <td>83.546035</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'min_samples_split': 25, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>81.454545</td>\n",
       "      <td>83.682771</td>\n",
       "      <td>...</td>\n",
       "      <td>85.036496</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>82.116788</td>\n",
       "      <td>83.515483</td>\n",
       "      <td>84.671533</td>\n",
       "      <td>82.969035</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.426715</td>\n",
       "      <td>0.347811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.840534         0.000676        83.163265         83.546035   \n",
       "1        0.779057         0.000609        83.163265         83.546035   \n",
       "2        0.773153         0.000608        83.163265         83.546035   \n",
       "3        0.771235         0.000603        83.163265         83.546035   \n",
       "4        0.775854         0.000615        83.163265         83.546035   \n",
       "5        0.776714         0.000663        83.163265         83.546035   \n",
       "6        0.777320         0.000605        83.163265         83.546035   \n",
       "7        0.772857         0.000607        83.163265         83.546035   \n",
       "8        0.777278         0.000606        83.163265         83.546035   \n",
       "9        0.775073         0.000616        83.163265         83.546035   \n",
       "10       0.791320         0.000634        83.163265         83.546035   \n",
       "11       0.785110         0.000613        83.163265         83.546035   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "0                3                      10   \n",
       "1                3                      15   \n",
       "2                3                      20   \n",
       "3                3                      25   \n",
       "4                4                      10   \n",
       "5                4                      15   \n",
       "6                4                      20   \n",
       "7                4                      25   \n",
       "8                5                      10   \n",
       "9                5                      15   \n",
       "10               5                      20   \n",
       "11               5                      25   \n",
       "\n",
       "                                         params  rank_test_score  \\\n",
       "0   {u'min_samples_split': 10, u'max_depth': 3}                1   \n",
       "1   {u'min_samples_split': 15, u'max_depth': 3}                1   \n",
       "2   {u'min_samples_split': 20, u'max_depth': 3}                1   \n",
       "3   {u'min_samples_split': 25, u'max_depth': 3}                1   \n",
       "4   {u'min_samples_split': 10, u'max_depth': 4}                1   \n",
       "5   {u'min_samples_split': 15, u'max_depth': 4}                1   \n",
       "6   {u'min_samples_split': 20, u'max_depth': 4}                1   \n",
       "7   {u'min_samples_split': 25, u'max_depth': 4}                1   \n",
       "8   {u'min_samples_split': 10, u'max_depth': 5}                1   \n",
       "9   {u'min_samples_split': 15, u'max_depth': 5}                1   \n",
       "10  {u'min_samples_split': 20, u'max_depth': 5}                1   \n",
       "11  {u'min_samples_split': 25, u'max_depth': 5}                1   \n",
       "\n",
       "    split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0           81.454545           83.682771       ...                 85.036496   \n",
       "1           81.454545           83.682771       ...                 85.036496   \n",
       "2           81.454545           83.682771       ...                 85.036496   \n",
       "3           81.454545           83.682771       ...                 85.036496   \n",
       "4           81.454545           83.682771       ...                 85.036496   \n",
       "5           81.454545           83.682771       ...                 85.036496   \n",
       "6           81.454545           83.682771       ...                 85.036496   \n",
       "7           81.454545           83.682771       ...                 85.036496   \n",
       "8           81.454545           83.682771       ...                 85.036496   \n",
       "9           81.454545           83.682771       ...                 85.036496   \n",
       "10          81.454545           83.682771       ...                 85.036496   \n",
       "11          81.454545           83.682771       ...                 85.036496   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            83.515483          82.116788           83.515483   \n",
       "1            83.515483          82.116788           83.515483   \n",
       "2            83.515483          82.116788           83.515483   \n",
       "3            83.515483          82.116788           83.515483   \n",
       "4            83.515483          82.116788           83.515483   \n",
       "5            83.515483          82.116788           83.515483   \n",
       "6            83.515483          82.116788           83.515483   \n",
       "7            83.515483          82.116788           83.515483   \n",
       "8            83.515483          82.116788           83.515483   \n",
       "9            83.515483          82.116788           83.515483   \n",
       "10           83.515483          82.116788           83.515483   \n",
       "11           83.515483          82.116788           83.515483   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           84.671533           82.969035      0.009733        0.000034   \n",
       "1           84.671533           82.969035      0.011207        0.000006   \n",
       "2           84.671533           82.969035      0.001926        0.000006   \n",
       "3           84.671533           82.969035      0.002325        0.000007   \n",
       "4           84.671533           82.969035      0.003135        0.000007   \n",
       "5           84.671533           82.969035      0.003052        0.000094   \n",
       "6           84.671533           82.969035      0.002686        0.000005   \n",
       "7           84.671533           82.969035      0.002586        0.000007   \n",
       "8           84.671533           82.969035      0.002679        0.000010   \n",
       "9           84.671533           82.969035      0.002100        0.000013   \n",
       "10          84.671533           82.969035      0.009245        0.000033   \n",
       "11          84.671533           82.969035      0.001621        0.000015   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         1.426715         0.347811  \n",
       "1         1.426715         0.347811  \n",
       "2         1.426715         0.347811  \n",
       "3         1.426715         0.347811  \n",
       "4         1.426715         0.347811  \n",
       "5         1.426715         0.347811  \n",
       "6         1.426715         0.347811  \n",
       "7         1.426715         0.347811  \n",
       "8         1.426715         0.347811  \n",
       "9         1.426715         0.347811  \n",
       "10        1.426715         0.347811  \n",
       "11        1.426715         0.347811  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best score: 83.163265\n",
      "best params: {'min_samples_split': 10, 'max_depth': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\"\"\n",
    "best score: %f\n",
    "best params: %s\n",
    "\"\"\" % (clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_tree = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if feat[0] <= 1.794: (gini: 0.961 samples: 1372 [762, 610])\n",
      "T-> if feat[1] <= 9.659: (gini: 0.607 samples: 890 [285, 605])\n",
      "  T-> if feat[0] <= -7.042: (gini: 0.568 samples: 831 [226, 605])\n",
      "    T-> 1\n",
      "    F-> 1\n",
      "  F-> if feat[0] <= -1.577: (gini: 0.000 samples: 59 [59, 0])\n",
      "    T-> 0\n",
      "    F-> 0\n",
      "F-> if feat[2] <= -4.942: (gini: 0.057 samples: 482 [477, 5])\n",
      "  T-> 1\n",
      "  F-> if feat[0] <= 1.794: (gini: 0.015 samples: 480 [477, 3])\n",
      "    T-> 0\n",
      "    F-> 0\n"
     ]
    }
   ],
   "source": [
    "display_tree(best_tree.tree_, best_tree.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References\n",
    "\n",
    "Original blog post I got the algorithm from: http://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "\n",
    "sklearn documentation on rolling your own estimator: http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator\n",
    "\n",
    "**NOTE** I did only the minimal work I found necessary to get this working, you'll probably want to do something like the TemplateClassifer to make things **completely** compatible. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
