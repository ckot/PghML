{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How to roll your own scikit-learn compatible algorithm\n",
    "\n",
    "\n",
    "First off you need to implement you algorithm as a class and provide named parameters with default values in the\n",
    "constructor\n",
    "\n",
    "ex) `def __init__(self, max_depth=5, min_samples_split=20)`\n",
    "\n",
    "then you will need to provide the following methods at the bare minimum:\n",
    "\n",
    "```\n",
    "def fit(self, X, y)\n",
    "    \"\"\"train your model\"\"\"\n",
    "\n",
    "def predict(self, X)\n",
    "    \"\"\"to make use of your model\"\"\"\n",
    "\n",
    "def score(self, X, y, sample_weight=None)\n",
    "    \"\"\"for evaluating your model's accuracy\"\"\"\n",
    "```  \n",
    "\n",
    "However, this will only get you so far, and primarily provides the same \"feel\" as a scikit learn estimator.  to make it compatible with more things, you should also implement:\n",
    "\n",
    "```\n",
    "def get_params(self, deep=True)\n",
    "    \"\"\"returns a dict of the current parameter values.\n",
    "    \n",
    "    It should accept the named parameter **deep** with a default value of **True** for compatability.\n",
    "    In most cases, you will ignore this value. If you have sub-estimators, this value signifies that the user\n",
    "    wants these params exposed as well\n",
    "    \"\"\"\n",
    "\n",
    "def set_params(self, **params)\n",
    "    \"\"\"Allows parameter values passed to the constructor to be modified\"\"\"\n",
    "```\n",
    "\n",
    "## What I've learned since my presentation\n",
    "\n",
    "I simply subclassed from `object`, and implemented the above interface. If I had instead subclassed from sklearn's  `base.BaseEstimator`, I would have inherited:\n",
    "\n",
    "* `get_params()`  - BaseEstimator introspects your __init__() and returns a dict of your named params mapped to their values\n",
    "* `set_params()`  - this method is always the same\n",
    "\n",
    "It also implements `__repr__()`, which makes use of `get_params()`, so you don't need to implement this method either\n",
    "\n",
    "\n",
    "If I had made use of `base.ClassifierMixin` I would have inherited:\n",
    "* `score()` - I wrote my own custom code for calculating accuracy.  this calls `sklearn.metrics.accuracy_score()` so you don't need to roll your own\n",
    "\n",
    "Also it automatically sets the following attributes for you:\n",
    "* `estimator_type_ = \"classifier\"`\n",
    "\n",
    "If instead you're implementing a regression estimator, you could make use of `base.RegressorMixin` which provides\n",
    "* `score()` which uses sklearn.metrics.r2_score\n",
    "\n",
    "and sets:\n",
    "* `estimator_type_ = \"regressor\"`\n",
    "\n",
    "\n",
    "Anyway, as you can see simply subclassing 'object' and providing the public interface described abovegot me really far.  \n",
    "\n",
    "If, however, I'd have subclassed from `base.BaseEstimator` and made use of either the `base.BaseClassifier` or `base.BaseRegresion` mixins, I could have reduced some of the boilerplate necessary to make my code scikit-learn compatible, and spendt more time on implementing the actual algoritm, meaning I'd have only needed to provide:\n",
    "* `fit()`\n",
    "* `predict()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# installs 'PghML' in sys.path (if it isn't there already)\n",
    "from config_notebook import setup_pgh_ml_path\n",
    "setup_pgh_ml_path()\n",
    "\n",
    "# loader function for my dataset\n",
    "from pgh_ml_py.datasets import load_banknote_authentication\n",
    "# my decision tree implementation\n",
    "from pgh_ml_py.sklearn_compat.tree.cart_decision_tree import CartDecisionTreeClassifier, display_tree\n",
    "\n",
    "# useful sklearn functions/Classes which we wish to be able to leverage (the point of making our code compatible)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, train_test_split\n",
    "# other dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# my custom dataset loader function. typically you'll have it return some fields using the conventions\n",
    "# data -> the features matrix\n",
    "# target -> the labels vector\n",
    "# in addition, I'm also returning 'dataframe' which is the original pandas dataframe I loaded, so we can analyze\n",
    "# the data as well\n",
    "dataset = load_banknote_authentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = dataset.dataframe\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 4)\n",
      "(1029,)\n",
      "(343, 4)\n",
      "(343,)\n"
     ]
    }
   ],
   "source": [
    "print train_X.shape\n",
    "print train_y.shape\n",
    "print test_X.shape\n",
    "print test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = CartDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CartDecisionTreeClassifier(criterion=u'gini', max_depth=5,\n",
       "              min_samples_split=20, splitter=u'best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Following sklearn's conventions for decision trees, my implementation's fit method sets the following 2 attributes:\n",
    "\n",
    "* `clf.tree_`  - the underlying representation of the decision tree\n",
    "\n",
    "* `clf.classes_` - the set of unique classes in y\n",
    "\n",
    "\n",
    "\n",
    "### Here I call my ad_hoc function, display_tree(), which understands my decision trees representation makes use of these attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if feat[0] <= -1.389: (impurity: 3.995 num_samples: 1029 [545 484])\n",
      "T-> if feat[0] <= -1.389: (impurity: 3.987 num_samples: 327 [ 36 291])\n",
      "  T-> 1\n",
      "  F-> 1\n",
      "F-> if feat[0] <= -1.119: (impurity: 3.993 num_samples: 702 [509 193])\n",
      "  T-> if feat[0] <= -1.119: (impurity: 3.798 num_samples: 23 [ 9 14])\n",
      "    T-> 1\n",
      "    F-> 1\n",
      "  F-> if feat[0] <= 0.191: (impurity: 3.993 num_samples: 679 [500 179])\n",
      "    T-> if feat[0] <= 0.191: (impurity: 3.971 num_samples: 147 [ 42 105])\n",
      "      T-> 1\n",
      "      F-> 1\n",
      "    F-> if feat[0] <= 3.999: (impurity: 3.992 num_samples: 532 [458  74])\n",
      "      T-> if feat[0] <= 1.208: (impurity: 3.989 num_samples: 413 [339  74])\n",
      "        T-> 0\n",
      "        F-> 0\n",
      "      F-> if feat[0] <= 4.340: (impurity: 3.965 num_samples: 119 [119])\n",
      "        T-> 0\n",
      "        F-> 0\n"
     ]
    }
   ],
   "source": [
    "display_tree(clf.tree_, clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ok, great, but let's actually try and do something with my tree.  Let's call predict() on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckot/PghML/venv/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## yikes!\n",
    "\n",
    "Ehat's happening here ??? As you can see, it *works* but spits out an ugly deprecation warning\n",
    "\n",
    "Sklearn classfiers predict methods expect an **array** of rows, so if we're passing in a single row of data we simply need to pass it as [row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([test_X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### And let's see how accurate my tree is by passing in full test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ok. \n",
    "That's fine for demonstrating how to fit/predict/score a single tree, but let's do a cross validation with 5 folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68      ,  0.55636364,  0.82846715,  0.81386861,  0.80291971])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, dataset.data, dataset.target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hmm. something looks **very** wrong here,  the original code scored ~80%.  Did I break something in my refactoring?  Lets take a look at the data (like I **should** have prior to doing anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  label\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  label\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ok,  I *think* I'm seeing a pattern. Let's print out some more of the dataset to make sure I'm not hallucinating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.621600</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.807300</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.545900</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.458600</td>\n",
       "      <td>-1.462100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.866000</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.924200</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.456600</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.011200</td>\n",
       "      <td>-3.594400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329240</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.571800</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.368400</td>\n",
       "      <td>9.67180</td>\n",
       "      <td>-3.960600</td>\n",
       "      <td>-3.162500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.591200</td>\n",
       "      <td>3.01290</td>\n",
       "      <td>0.728880</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.092200</td>\n",
       "      <td>-6.81000</td>\n",
       "      <td>8.463600</td>\n",
       "      <td>-0.602160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.203200</td>\n",
       "      <td>5.75880</td>\n",
       "      <td>-0.753450</td>\n",
       "      <td>-0.612510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.535600</td>\n",
       "      <td>9.17720</td>\n",
       "      <td>-2.271800</td>\n",
       "      <td>-0.735350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.224700</td>\n",
       "      <td>8.77790</td>\n",
       "      <td>-2.213500</td>\n",
       "      <td>-0.806470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.989900</td>\n",
       "      <td>-2.70660</td>\n",
       "      <td>2.394600</td>\n",
       "      <td>0.862910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.899300</td>\n",
       "      <td>7.66250</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>-3.110800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.576800</td>\n",
       "      <td>10.84300</td>\n",
       "      <td>2.546200</td>\n",
       "      <td>-2.936200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.404000</td>\n",
       "      <td>8.72610</td>\n",
       "      <td>-2.991500</td>\n",
       "      <td>-0.572420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.676500</td>\n",
       "      <td>-3.38950</td>\n",
       "      <td>3.489600</td>\n",
       "      <td>1.477100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.671900</td>\n",
       "      <td>3.06460</td>\n",
       "      <td>0.371580</td>\n",
       "      <td>0.586190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.803550</td>\n",
       "      <td>2.84730</td>\n",
       "      <td>4.343900</td>\n",
       "      <td>0.601700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.447900</td>\n",
       "      <td>-4.87940</td>\n",
       "      <td>8.342800</td>\n",
       "      <td>-2.108600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.242300</td>\n",
       "      <td>11.02720</td>\n",
       "      <td>-4.353000</td>\n",
       "      <td>-4.101300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.786700</td>\n",
       "      <td>7.89020</td>\n",
       "      <td>-2.619600</td>\n",
       "      <td>-0.487080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.329200</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.571800</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.936200</td>\n",
       "      <td>10.16220</td>\n",
       "      <td>-3.823500</td>\n",
       "      <td>-4.017200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.935840</td>\n",
       "      <td>8.88550</td>\n",
       "      <td>-1.683100</td>\n",
       "      <td>-1.659900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.433800</td>\n",
       "      <td>9.88700</td>\n",
       "      <td>-4.679500</td>\n",
       "      <td>-3.748300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.705700</td>\n",
       "      <td>-5.49810</td>\n",
       "      <td>8.336800</td>\n",
       "      <td>-2.871500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.143200</td>\n",
       "      <td>-3.74130</td>\n",
       "      <td>5.577700</td>\n",
       "      <td>-0.635780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.382140</td>\n",
       "      <td>8.39090</td>\n",
       "      <td>2.162400</td>\n",
       "      <td>-3.740500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.563300</td>\n",
       "      <td>9.81870</td>\n",
       "      <td>-4.411300</td>\n",
       "      <td>-3.225800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.890600</td>\n",
       "      <td>-3.35840</td>\n",
       "      <td>3.420200</td>\n",
       "      <td>1.090500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>-1.747900</td>\n",
       "      <td>-5.82300</td>\n",
       "      <td>5.869900</td>\n",
       "      <td>1.212000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>-0.959230</td>\n",
       "      <td>-6.71280</td>\n",
       "      <td>4.985700</td>\n",
       "      <td>0.328860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1.345100</td>\n",
       "      <td>0.23589</td>\n",
       "      <td>-1.878500</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>2.227900</td>\n",
       "      <td>4.09510</td>\n",
       "      <td>-4.803700</td>\n",
       "      <td>-2.111200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1.257200</td>\n",
       "      <td>4.87310</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-5.874100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>-5.385700</td>\n",
       "      <td>9.12140</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-5.918100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>-2.978600</td>\n",
       "      <td>2.34450</td>\n",
       "      <td>0.526670</td>\n",
       "      <td>-0.401730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>-1.585100</td>\n",
       "      <td>-2.15620</td>\n",
       "      <td>1.708200</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>-0.218880</td>\n",
       "      <td>-2.20380</td>\n",
       "      <td>-0.095400</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1.318300</td>\n",
       "      <td>1.90170</td>\n",
       "      <td>-3.311100</td>\n",
       "      <td>0.065071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1.489600</td>\n",
       "      <td>3.42880</td>\n",
       "      <td>-4.030900</td>\n",
       "      <td>-1.425900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>0.115920</td>\n",
       "      <td>3.22190</td>\n",
       "      <td>-3.430200</td>\n",
       "      <td>-2.845700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>-3.392400</td>\n",
       "      <td>3.35640</td>\n",
       "      <td>-0.720040</td>\n",
       "      <td>-3.523300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>-6.163200</td>\n",
       "      <td>8.70960</td>\n",
       "      <td>-0.216210</td>\n",
       "      <td>-3.634500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>-4.078600</td>\n",
       "      <td>2.92390</td>\n",
       "      <td>0.870260</td>\n",
       "      <td>-0.653890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>-2.589900</td>\n",
       "      <td>-0.39110</td>\n",
       "      <td>0.934520</td>\n",
       "      <td>0.429720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-0.19038</td>\n",
       "      <td>-0.905970</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>0.066129</td>\n",
       "      <td>2.49140</td>\n",
       "      <td>-2.940100</td>\n",
       "      <td>-0.621560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>-0.247450</td>\n",
       "      <td>1.93680</td>\n",
       "      <td>-2.469700</td>\n",
       "      <td>-0.805180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>-1.573200</td>\n",
       "      <td>1.06360</td>\n",
       "      <td>-0.712320</td>\n",
       "      <td>-0.838800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>-2.166800</td>\n",
       "      <td>1.59330</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>-1.678000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>-1.166700</td>\n",
       "      <td>-1.42370</td>\n",
       "      <td>2.924100</td>\n",
       "      <td>0.661190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>-2.839100</td>\n",
       "      <td>-6.63000</td>\n",
       "      <td>10.484900</td>\n",
       "      <td>-0.421130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>-4.504600</td>\n",
       "      <td>-5.81260</td>\n",
       "      <td>10.886700</td>\n",
       "      <td>-0.528460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>-2.410000</td>\n",
       "      <td>3.74330</td>\n",
       "      <td>-0.402150</td>\n",
       "      <td>-1.295300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.406140</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.450100</td>\n",
       "      <td>-0.559490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.388700</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.477400</td>\n",
       "      <td>0.341790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.750300</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.593200</td>\n",
       "      <td>-2.777100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.563700</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.393000</td>\n",
       "      <td>-1.282300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.541900</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.684200</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness   curtosis   entropy  label\n",
       "0     3.621600   8.66610  -2.807300 -0.446990      0\n",
       "1     4.545900   8.16740  -2.458600 -1.462100      0\n",
       "2     3.866000  -2.63830   1.924200  0.106450      0\n",
       "3     3.456600   9.52280  -4.011200 -3.594400      0\n",
       "4     0.329240  -4.45520   4.571800 -0.988800      0\n",
       "5     4.368400   9.67180  -3.960600 -3.162500      0\n",
       "6     3.591200   3.01290   0.728880  0.564210      0\n",
       "7     2.092200  -6.81000   8.463600 -0.602160      0\n",
       "8     3.203200   5.75880  -0.753450 -0.612510      0\n",
       "9     1.535600   9.17720  -2.271800 -0.735350      0\n",
       "10    1.224700   8.77790  -2.213500 -0.806470      0\n",
       "11    3.989900  -2.70660   2.394600  0.862910      0\n",
       "12    1.899300   7.66250   0.153940 -3.110800      0\n",
       "13   -1.576800  10.84300   2.546200 -2.936200      0\n",
       "14    3.404000   8.72610  -2.991500 -0.572420      0\n",
       "15    4.676500  -3.38950   3.489600  1.477100      0\n",
       "16    2.671900   3.06460   0.371580  0.586190      0\n",
       "17    0.803550   2.84730   4.343900  0.601700      0\n",
       "18    1.447900  -4.87940   8.342800 -2.108600      0\n",
       "19    5.242300  11.02720  -4.353000 -4.101300      0\n",
       "20    5.786700   7.89020  -2.619600 -0.487080      0\n",
       "21    0.329200  -4.45520   4.571800 -0.988800      0\n",
       "22    3.936200  10.16220  -3.823500 -4.017200      0\n",
       "23    0.935840   8.88550  -1.683100 -1.659900      0\n",
       "24    4.433800   9.88700  -4.679500 -3.748300      0\n",
       "25    0.705700  -5.49810   8.336800 -2.871500      0\n",
       "26    1.143200  -3.74130   5.577700 -0.635780      0\n",
       "27   -0.382140   8.39090   2.162400 -3.740500      0\n",
       "28    6.563300   9.81870  -4.411300 -3.225800      0\n",
       "29    4.890600  -3.35840   3.420200  1.090500      0\n",
       "...        ...       ...        ...       ...    ...\n",
       "1342 -1.747900  -5.82300   5.869900  1.212000      1\n",
       "1343 -0.959230  -6.71280   4.985700  0.328860      1\n",
       "1344  1.345100   0.23589  -1.878500  1.325800      1\n",
       "1345  2.227900   4.09510  -4.803700 -2.111200      1\n",
       "1346  1.257200   4.87310  -5.286100 -5.874100      1\n",
       "1347 -5.385700   9.12140  -0.419290 -5.918100      1\n",
       "1348 -2.978600   2.34450   0.526670 -0.401730      1\n",
       "1349 -1.585100  -2.15620   1.708200  0.901700      1\n",
       "1350 -0.218880  -2.20380  -0.095400  0.564210      1\n",
       "1351  1.318300   1.90170  -3.311100  0.065071      1\n",
       "1352  1.489600   3.42880  -4.030900 -1.425900      1\n",
       "1353  0.115920   3.22190  -3.430200 -2.845700      1\n",
       "1354 -3.392400   3.35640  -0.720040 -3.523300      1\n",
       "1355 -6.163200   8.70960  -0.216210 -3.634500      1\n",
       "1356 -4.078600   2.92390   0.870260 -0.653890      1\n",
       "1357 -2.589900  -0.39110   0.934520  0.429720      1\n",
       "1358 -1.011600  -0.19038  -0.905970  0.003003      1\n",
       "1359  0.066129   2.49140  -2.940100 -0.621560      1\n",
       "1360 -0.247450   1.93680  -2.469700 -0.805180      1\n",
       "1361 -1.573200   1.06360  -0.712320 -0.838800      1\n",
       "1362 -2.166800   1.59330   0.045122 -1.678000      1\n",
       "1363 -1.166700  -1.42370   2.924100  0.661190      1\n",
       "1364 -2.839100  -6.63000  10.484900 -0.421130      1\n",
       "1365 -4.504600  -5.81260  10.886700 -0.528460      1\n",
       "1366 -2.410000   3.74330  -0.402150 -1.295300      1\n",
       "1367  0.406140   1.34920  -1.450100 -0.559490      1\n",
       "1368 -1.388700  -4.87730   6.477400  0.341790      1\n",
       "1369 -3.750300 -13.45860  17.593200 -2.777100      1\n",
       "1370 -3.563700  -8.38270  12.393000 -1.282300      1\n",
       "1371 -2.541900  -0.65804   2.684200  1.195200      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Here's the problem with what I did\n",
    "\n",
    "It turns out that my original function which created k-folds was randomizing (shuffling) the order of records, but that's not happening here\n",
    "\n",
    "As you can see, **all** of the rows labeled **0** are in the **1st half** of the dataset while all the rows labeled **1** are in the **2nd half** of the dataset.  \n",
    "\n",
    "By default, if you simply pass in an int for the cv param it uses KFold which doesn't deal with this. \n",
    "\n",
    "### Let's make use of StratifiedKFold instead to make sure that all of our folds have the classes balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=np.random.RandomState(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55458515,  0.74179431,  0.55579869])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, dataset.data, dataset.target, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ok, great!  These values are pretty much in sync with the original blog post I based this off of.  That's a relief - I didn't break anything in all of my refactoring.\n",
    "\n",
    "So far, I've simply made use of my class using it's default values of max_depth=5 and min_samples_split=20\n",
    "\n",
    "### Let's make use of sklearn's GridSearchCV to try automatically optimize values for these parameters. \n",
    "\n",
    "Of course, this can take a while, so I'll keep the ranges of values to a reasonable size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(3, 6), 'min_samples_split': range(10, 26, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt = CartDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedKFold(n_splits=3,\n",
      "        random_state=<mtrand.RandomState object at 0x7fe67c4fef00>,\n",
      "        shuffle=True),\n",
      "       error_score='raise',\n",
      "       estimator=CartDecisionTreeClassifier(criterion=u'gini', max_depth=5,\n",
      "              min_samples_split=20, splitter=u'best'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'min_samples_split': [10, 15, 20, 25], 'max_depth': [3, 4, 5]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(dt, parameters, cv=cv, verbose=True)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3,\n",
       "        random_state=<mtrand.RandomState object at 0x7fe67c4fef00>,\n",
       "        shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=CartDecisionTreeClassifier(criterion=u'gini', max_depth=5,\n",
       "              min_samples_split=20, splitter=u'best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [10, 15, 20, 25], 'max_depth': [3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### After running fit(), the GridSearchCV has a bunch of attributes set.  The ones I found most useful were:\n",
    "* cv\\_results\\_      - lots of details which can be imported into pandas as a dataframe\n",
    "* best\\_score\\_      - score of the best result\n",
    "* best\\_params\\_     - dict of the best parameter values discovered\n",
    "* best\\_estimator\\_  - the best estimator object (useful as you can inspect it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.104398</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'min_samples_split': 10, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>0.853014</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.203046</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'min_samples_split': 15, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>0.685075</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.162250</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'min_samples_split': 20, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>0.655186</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.009429</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'min_samples_split': 25, u'max_depth': 3}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>0.744992</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.367380</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'min_samples_split': 10, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.087559</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.259733</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'min_samples_split': 15, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.120363</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.246996</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'min_samples_split': 20, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.121069</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.240975</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'min_samples_split': 25, u'max_depth': 4}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.106430</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.260208</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'min_samples_split': 10, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.124908</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.247306</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'min_samples_split': 15, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.110683</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.229216</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'min_samples_split': 20, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.115288</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.225755</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.666978</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'min_samples_split': 25, u'max_depth': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831878</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.575492</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.555799</td>\n",
       "      <td>0.555191</td>\n",
       "      <td>1.102802</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        4.104398         0.001884         0.654519          0.666978   \n",
       "1        4.203046         0.001887         0.654519          0.666978   \n",
       "2        4.162250         0.001863         0.654519          0.666978   \n",
       "3        4.009429         0.001956         0.654519          0.666978   \n",
       "4        4.367380         0.002060         0.654519          0.666978   \n",
       "5        4.259733         0.002049         0.654519          0.666978   \n",
       "6        4.246996         0.002032         0.654519          0.666978   \n",
       "7        4.240975         0.002047         0.654519          0.666978   \n",
       "8        4.260208         0.002059         0.654519          0.666978   \n",
       "9        4.247306         0.002039         0.654519          0.666978   \n",
       "10       4.229216         0.002041         0.654519          0.666978   \n",
       "11       4.225755         0.002048         0.654519          0.666978   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "0                3                      10   \n",
       "1                3                      15   \n",
       "2                3                      20   \n",
       "3                3                      25   \n",
       "4                4                      10   \n",
       "5                4                      15   \n",
       "6                4                      20   \n",
       "7                4                      25   \n",
       "8                5                      10   \n",
       "9                5                      15   \n",
       "10               5                      20   \n",
       "11               5                      25   \n",
       "\n",
       "                                         params  rank_test_score  \\\n",
       "0   {u'min_samples_split': 10, u'max_depth': 3}                1   \n",
       "1   {u'min_samples_split': 15, u'max_depth': 3}                1   \n",
       "2   {u'min_samples_split': 20, u'max_depth': 3}                1   \n",
       "3   {u'min_samples_split': 25, u'max_depth': 3}                1   \n",
       "4   {u'min_samples_split': 10, u'max_depth': 4}                1   \n",
       "5   {u'min_samples_split': 15, u'max_depth': 4}                1   \n",
       "6   {u'min_samples_split': 20, u'max_depth': 4}                1   \n",
       "7   {u'min_samples_split': 25, u'max_depth': 4}                1   \n",
       "8   {u'min_samples_split': 10, u'max_depth': 5}                1   \n",
       "9   {u'min_samples_split': 15, u'max_depth': 5}                1   \n",
       "10  {u'min_samples_split': 20, u'max_depth': 5}                1   \n",
       "11  {u'min_samples_split': 25, u'max_depth': 5}                1   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            0.831878             0.85558           0.575492   \n",
       "1            0.831878             0.85558           0.575492   \n",
       "2            0.831878             0.85558           0.575492   \n",
       "3            0.831878             0.85558           0.575492   \n",
       "4            0.831878             0.85558           0.575492   \n",
       "5            0.831878             0.85558           0.575492   \n",
       "6            0.831878             0.85558           0.575492   \n",
       "7            0.831878             0.85558           0.575492   \n",
       "8            0.831878             0.85558           0.575492   \n",
       "9            0.831878             0.85558           0.575492   \n",
       "10           0.831878             0.85558           0.575492   \n",
       "11           0.831878             0.85558           0.575492   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0             0.590164           0.555799            0.555191      0.853014   \n",
       "1             0.590164           0.555799            0.555191      0.685075   \n",
       "2             0.590164           0.555799            0.555191      0.655186   \n",
       "3             0.590164           0.555799            0.555191      0.744992   \n",
       "4             0.590164           0.555799            0.555191      1.087559   \n",
       "5             0.590164           0.555799            0.555191      1.120363   \n",
       "6             0.590164           0.555799            0.555191      1.121069   \n",
       "7             0.590164           0.555799            0.555191      1.106430   \n",
       "8             0.590164           0.555799            0.555191      1.124908   \n",
       "9             0.590164           0.555799            0.555191      1.110683   \n",
       "10            0.590164           0.555799            0.555191      1.115288   \n",
       "11            0.590164           0.555799            0.555191      1.102802   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.000172        0.125806         0.134124  \n",
       "1         0.000150        0.125806         0.134124  \n",
       "2         0.000148        0.125806         0.134124  \n",
       "3         0.000122        0.125806         0.134124  \n",
       "4         0.000306        0.125806         0.134124  \n",
       "5         0.000362        0.125806         0.134124  \n",
       "6         0.000361        0.125806         0.134124  \n",
       "7         0.000331        0.125806         0.134124  \n",
       "8         0.000329        0.125806         0.134124  \n",
       "9         0.000314        0.125806         0.134124  \n",
       "10        0.000324        0.125806         0.134124  \n",
       "11        0.000338        0.125806         0.134124  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best score: 0.654519\n",
      "best params: {'min_samples_split': 10, 'max_depth': 3}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\"\"\n",
    "best score: %f\n",
    "best params: %s\n",
    "\"\"\" % (clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_tree = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if feat[0] <= 4.676: (impurity: 3.996 num_samples: 1372 [762 610])\n",
      "T-> if feat[0] <= 4.368: (impurity: 3.996 num_samples: 1301 [691 610])\n",
      "  T-> if feat[0] <= 0.936: (impurity: 3.996 num_samples: 1273 [663 610])\n",
      "    T-> 1\n",
      "    F-> 0\n",
      "  F-> if feat[0] <= 4.546: (impurity: 3.849 num_samples: 28 [28])\n",
      "    T-> 0\n",
      "    F-> 0\n",
      "F-> if feat[0] <= 5.402: (impurity: 3.942 num_samples: 71 [71])\n",
      "  T-> if feat[0] <= 5.242: (impurity: 3.915 num_samples: 49 [49])\n",
      "    T-> 0\n",
      "    F-> 0\n",
      "  F-> if feat[0] <= 5.787: (impurity: 3.810 num_samples: 22 [22])\n",
      "    T-> 0\n",
      "    F-> 0\n"
     ]
    }
   ],
   "source": [
    "display_tree(best_tree.tree_, best_tree.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Going Forward\n",
    "\n",
    "Decision Trees in sklearn provide the following attributes\n",
    "* `classes_` - I implemented this one. simply the unique set of labels \n",
    "\n",
    "\n",
    "* `tree_` - I implemented this as well, simply provides access to the data structure which represents the tree\n",
    "\n",
    "\n",
    "* `n_features_` -  I *believe* this should be the number of columns in X, or simply `X.shape[1]`\n",
    "\n",
    "\n",
    "* `n_outputs_` - I *believe* this represents how many columns are in y, which is typically 1, but is computed as `y.ndim`  Perhaps this is more useful when doing multi-label stuff\n",
    "\n",
    "\n",
    "* `n_classes_` - I *believe* this should simply be  `len(classes_)`\n",
    "\n",
    "\n",
    "* `max_features_` - how many features were considered when determining the best splits\n",
    "\n",
    "Also they provide more named-parameters in their constructors. I'm currently providing:\n",
    "* `max_depth`\n",
    "\n",
    "\n",
    "* `min_samples_split`\n",
    "\n",
    "while sklearn decision trees also provide the following named parameters in their constructors:\n",
    "\n",
    "* For classifiers:\n",
    "    * `criterion=\"gini\"`  the other choice being \"entropy\". I could add support for using this as my metric for selecting the best split\n",
    "* For regressors:\n",
    "    * `criterion=\"mse\"`  the other choices being \"friedman_mse\", and \"mae\"\n",
    " \n",
    " \n",
    "* `splitter=\"best\"`  the other choice being \"random\". My implementation is \"best\".  I *believe* \"random\" would be useful for generating numerous trees for Random Forests\n",
    "\n",
    "\n",
    "* `max_features` defaults to the number of features, different values determine how many features should be considered when trying to determine the best split\n",
    "\n",
    "\n",
    "* `min_samples_leaf` the minimum number of samples required to represent a leaf node. I'm guessing this is used to prune the parent node and replace it with a leaf\n",
    "\n",
    "\n",
    "* `max_leaf_nodes=None` - grows tree with 'max_leaf_nodes' in best-first fashion. best nodes are defined as relative reduction in impurity. If none, unlimited number of leaf nodes\n",
    "\n",
    "\n",
    "* `min_weight_fraction_leaf=0` - minimum weighted fraction of the sum total of weights (of all input samples) required to be a leaf node. 0 means samples all have the same weight\n",
    "\n",
    "\n",
    "* `class_weight=None`  if 'None' all classes have weight of 1, if \"balanced\" each class's weight is inversely proportional to class frequencies in the y. can also be a dict of {class_label: weight, ...} or for multi-label a list of dicts in this format\n",
    "\n",
    "\n",
    "* `random_state=None` - scikit-learn always randomizes the feature indices to use when calculating splits, even if max_features is the same as n_features_.  this parameter simply gives you control to make multiple runs deterministic\n",
    "\n",
    "\n",
    "* `min_impurity_split=1e-7` threshold to prevent splits if a node's impurity is below, and instead generate a leaf node\n",
    "\n",
    "\n",
    "* `presort=False` whether to presort the data to attempt to speed up finding the best splits. A setting of True may slow down fitting of large datasets (if max_depth is too high), but may speed up things up for small datasets \n",
    "\n",
    "\n",
    "Perhaps, by incorporating such hyper-parameters into my algorithm, and thus being able to search for the optimal values, I improve the trees I generate.  \n",
    "\n",
    "Again, my purpose isn't to re-implement scikit-learn's decision trees, but rather implement an algoritm which is compatable with sklearn.  Figuring out what additional hyper-parameters are relevant to decision trees would simply allow me to explore improving the algorithm.  Perhaps other hyper-parameters could be found from different implementations or my own ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References\n",
    "\n",
    "Original blog post I got the algorithm from: http://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "\n",
    "sklearn documentation on rolling your own estimator: http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
